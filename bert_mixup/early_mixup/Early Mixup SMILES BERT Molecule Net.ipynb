{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a49dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/23/2022 00:11:22 - INFO - deepchem.molnet.load_function.molnet_loader -   About to featurize bace_c dataset.\n",
      "12/23/2022 00:11:22 - INFO - deepchem.data.data_loader -   Loading raw samples now.\n",
      "12/23/2022 00:11:22 - INFO - deepchem.data.data_loader -   shard_size: 8192\n",
      "12/23/2022 00:11:22 - INFO - deepchem.utils.data_utils -   About to start loading CSV from /var/folders/s4/4l6cbdrn7cq2m4vs14xz9qpm0000gn/T/bace.csv\n",
      "12/23/2022 00:11:22 - INFO - deepchem.utils.data_utils -   Loading shard 1 of size 8192.\n",
      "12/23/2022 00:11:22 - INFO - deepchem.data.data_loader -   About to featurize shard.\n",
      "12/23/2022 00:11:22 - INFO - deepchem.feat.base_classes -   Featurizing datapoint 0\n",
      "12/23/2022 00:11:29 - INFO - deepchem.feat.base_classes -   Featurizing datapoint 1000\n",
      "12/23/2022 00:11:32 - INFO - deepchem.data.data_loader -   TIMING: featurizing shard 0 took 9.532 s\n",
      "12/23/2022 00:11:32 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 9.732 s\n",
      "12/23/2022 00:11:32 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:32 - INFO - deepchem.molnet.load_function.molnet_loader -   About to split dataset with ScaffoldSplitter splitter.\n",
      "12/23/2022 00:11:32 - INFO - deepchem.splits.splitters -   Computing train/valid/test indices\n",
      "12/23/2022 00:11:32 - INFO - deepchem.splits.splitters -   About to generate scaffolds\n",
      "12/23/2022 00:11:32 - INFO - deepchem.splits.splitters -   Generating scaffold 0/1513\n",
      "12/23/2022 00:11:32 - INFO - deepchem.splits.splitters -   Generating scaffold 1000/1513\n",
      "12/23/2022 00:11:33 - INFO - deepchem.splits.splitters -   About to sort in scaffold sets\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Constructing selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Selecting from input shard 1/1 for selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.090 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Constructing selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Selecting from input shard 1/1 for selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.024 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Constructing selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Selecting from input shard 1/1 for selection output shard 1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.027 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.molnet.load_function.molnet_loader -   About to transform data.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Transforming shard 0/1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.074 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: transforming took 0.084 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Transforming shard 0/1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.019 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: transforming took 0.028 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Transforming shard 0/1\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: dataset construction took 0.018 s\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   Loading dataset from disk.\n",
      "12/23/2022 00:11:33 - INFO - deepchem.data.datasets -   TIMING: transforming took 0.024 s\n"
     ]
    }
   ],
   "source": [
    "from deepchem.molnet import load_bace_classification, load_bbbp\n",
    "import numpy as np\n",
    "\n",
    "from simcse import SimCSE\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from args_parser import parse_args\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "datasets = {\n",
    "        \"bace\": load_bace_classification,\n",
    "        \"bbbp\": load_bbbp\n",
    "        }\n",
    "\n",
    "sys.argv = ['']\n",
    "args = parse_args()\n",
    "\n",
    "args.samples_per_class=250\n",
    "args.n_augment = 0\n",
    "\n",
    "\n",
    "input_dim = 512\n",
    "output_dim = args.num_labels\n",
    "set_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "_, datasets, _ = datasets.get(args.dataset_name)(reload=False)\n",
    "(train_dataset, valid_dataset, test_dataset) = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcb772e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdb3e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at shahrukhx01/muv2x-simcse-smole-bert were not used when initializing BertModel: ['mlp.dense.bias', 'mlp.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at shahrukhx01/muv2x-simcse-smole-bert and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 8/8 [00:26<00:00,  3.28s/it]\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.52s/it]\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 1 | Loss : 0.695096093416214\n",
      "Validation =>  Epoch : 1 | Loss : 0.688141942024231 | AUROC score: 0.5943496801705758 \n",
      "Selecting the model...\n",
      "Training =>  Epoch : 2 | Loss : 0.6863942503929138\n",
      "Validation =>  Epoch : 2 | Loss : 0.6837015151977539 | AUROC score: 0.6186922530206113 \n",
      "Selecting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 3 | Loss : 0.6469144523143768\n",
      "Validation =>  Epoch : 3 | Loss : 0.6984891295433044 | AUROC score: 0.6592039800995024 \n",
      "Selecting the model...\n",
      "Training =>  Epoch : 4 | Loss : 0.5581906318664551\n",
      "Validation =>  Epoch : 4 | Loss : 0.737140417098999 | AUROC score: 0.6901208244491827 \n",
      "Selecting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 5 | Loss : 0.507535719871521\n",
      "Validation =>  Epoch : 5 | Loss : 0.748183012008667 | AUROC score: 0.6743070362473348 \n",
      "Training =>  Epoch : 6 | Loss : 0.44030154645442965\n",
      "Validation =>  Epoch : 6 | Loss : 0.6792479157447815 | AUROC score: 0.7036247334754797 \n",
      "Selecting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 7 | Loss : 0.4372164040803909\n",
      "Validation =>  Epoch : 7 | Loss : 0.676410973072052 | AUROC score: 0.71090973702914 \n",
      "Selecting the model...\n",
      "Training =>  Epoch : 8 | Loss : 0.4102799415588379\n",
      "Validation =>  Epoch : 8 | Loss : 0.685738205909729 | AUROC score: 0.7205046197583511 \n",
      "Selecting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 9 | Loss : 0.3826268076896667\n",
      "Validation =>  Epoch : 9 | Loss : 0.6415461897850037 | AUROC score: 0.7133972992181947 \n",
      "Training =>  Epoch : 10 | Loss : 0.3587747007608414\n",
      "Validation =>  Epoch : 10 | Loss : 0.7046258449554443 | AUROC score: 0.71090973702914 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 11 | Loss : 0.3310509964823723\n",
      "Validation =>  Epoch : 11 | Loss : 0.7430493831634521 | AUROC score: 0.7100213219616206 \n",
      "Training =>  Epoch : 12 | Loss : 0.3415596142411232\n",
      "Validation =>  Epoch : 12 | Loss : 0.7512920498847961 | AUROC score: 0.7093105899076049 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 13 | Loss : 0.31924952417612074\n",
      "Validation =>  Epoch : 13 | Loss : 0.7765250205993652 | AUROC score: 0.7151741293532339 \n",
      "Training =>  Epoch : 14 | Loss : 0.27114118486642835\n",
      "Validation =>  Epoch : 14 | Loss : 0.7479512691497803 | AUROC score: 0.7187277896233119 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 15 | Loss : 0.2824199602007866\n",
      "Validation =>  Epoch : 15 | Loss : 0.7969406843185425 | AUROC score: 0.7192608386638237 \n",
      "Training =>  Epoch : 16 | Loss : 0.30133824050426483\n",
      "Validation =>  Epoch : 16 | Loss : 0.7900192141532898 | AUROC score: 0.7022032693674485 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 17 | Loss : 0.2845265582203865\n",
      "Validation =>  Epoch : 17 | Loss : 0.9110234975814819 | AUROC score: 0.7162402274342574 \n",
      "Training =>  Epoch : 18 | Loss : 0.27125139385461805\n",
      "Validation =>  Epoch : 18 | Loss : 0.8660262227058411 | AUROC score: 0.714641080312722 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:167: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training =>  Epoch : 19 | Loss : 0.24421080946922302\n",
      "Validation =>  Epoch : 19 | Loss : 0.9373683333396912 | AUROC score: 0.697228144989339 \n",
      "Training =>  Epoch : 20 | Loss : 0.2786246299743652\n",
      "Validation =>  Epoch : 20 | Loss : 0.8990718722343445 | AUROC score: 0.6982942430703625 \n",
      "Test => AUROC score: 0.7673913043478261 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-555da9c8f486>:204: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n",
      "<ipython-input-28-555da9c8f486>:242: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  targets = torch.LongTensor([x.item() for x in list(targets)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SimCSE(\"shahrukhx01/muv2x-simcse-smole-bert\")\n",
    "train_indices = []\n",
    "\n",
    "def embed_smiles(smiles):\n",
    "    embeddings = model.encode(smiles)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "train_labels = [y[0] for y in train_dataset.y]\n",
    "label_df = pd.DataFrame(train_labels, columns=[\"labels\"])\n",
    "if args.samples_per_class > 0:\n",
    "    np.random.seed()\n",
    "    tp = np.random.choice(\n",
    "        list(label_df[label_df[\"labels\"] == 1].index),\n",
    "        args.samples_per_class,\n",
    "        replace=False,\n",
    "    )\n",
    "    tn = np.random.choice(\n",
    "        list(label_df[label_df[\"labels\"] == 0].index),\n",
    "        args.samples_per_class,\n",
    "        replace=False,\n",
    "    )\n",
    "    train_indices = list(tp) + list(tn)\n",
    "    \n",
    "np.random.seed()\n",
    "\n",
    "train_smiles = train_dataset.ids[train_indices]\n",
    "train_embeddings = embed_smiles(smiles=list(train_smiles))\n",
    "train_labels = [y[0] for y in train_dataset.y[train_indices]]\n",
    "\n",
    "val_smiles = valid_dataset.ids\n",
    "val_embeddings = embed_smiles(smiles=list(val_smiles))\n",
    "val_labels = [y[0] for y in valid_dataset.y]\n",
    "\n",
    "test_smiles = test_dataset.ids\n",
    "test_embeddings = embed_smiles(smiles=list(test_smiles))\n",
    "test_labels = [y[0] for y in test_dataset.y]\n",
    "\n",
    "def mixup_augment(embedding1, embedding2, label1, label2, lamda):\n",
    "    embedding_output = lam * embedding1 + (1.0 - lam) * embedding2\n",
    "    label_output = lam * label1 + (1.0 - lam) * label2\n",
    "    return (embedding_output, label_output)\n",
    "\n",
    "augmented_embeds, augmented_labels = [], []\n",
    "if args.n_augment:\n",
    "    for idx, (train_embedding, train_label) in enumerate(zip(train_embeddings, train_labels)):\n",
    "        train_embeddings_idx = np.array([_idx for _idx in range(len(train_embeddings)) if _idx!=idx])\n",
    "        for i in range(args.n_augment):\n",
    "            np.random.seed()\n",
    "            lam = np.random.beta(args.alpha, args.alpha)\n",
    "            embedding2_idx = np.random.choice(train_embeddings_idx, replace=False)\n",
    "            embedding2 = train_embeddings[embedding2_idx, :]\n",
    "            label2 = train_labels[embedding2_idx]\n",
    "            aug_embed, aug_label =  mixup_augment(embedding1=train_embedding, embedding2=embedding2, label1=train_label+1, label2=label2+1, lamda=lam)\n",
    "            aug_label = aug_label-1\n",
    "            augmented_embeds.append(aug_embed)\n",
    "            augmented_labels.append(aug_label)\n",
    "\n",
    "train_embeddings_augmented, train_labels_augmented = None, None\n",
    "\n",
    "if len(augmented_embeds):\n",
    "    augmented_embeds = torch.stack(augmented_embeds)\n",
    "    train_embeddings_augmented = torch.cat([train_embeddings, augmented_embeds])\n",
    "    train_labels_augmented = train_labels + augmented_labels\n",
    "else:\n",
    "    train_embeddings_augmented, train_labels_augmented = train_embeddings, train_labels\n",
    "    \n",
    "train_data = TensorDataset(\n",
    "            train_embeddings_augmented,\n",
    "            torch.Tensor(train_labels_augmented)\n",
    "        )\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=args.batch_size\n",
    ")\n",
    "\n",
    "\n",
    "val_data = TensorDataset(\n",
    "            val_embeddings,\n",
    "            torch.Tensor(val_labels)\n",
    "        )\n",
    "val_sampler = RandomSampler(val_data)\n",
    "val_dataloader = DataLoader(\n",
    "    val_data, sampler=val_sampler, batch_size=len(val_data)\n",
    ")\n",
    "\n",
    "\n",
    "test_data = TensorDataset(\n",
    "            test_embeddings,\n",
    "            torch.Tensor(test_labels)\n",
    "        )\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data, sampler=test_sampler, batch_size=len(test_data)\n",
    ")\n",
    "\n",
    "\n",
    "class MolNet(nn.Module):\n",
    "    \"\"\"\n",
    "    This class is created to specify the Neural Network on which vectorized datasets we have created previously\n",
    "    is trained on, validated and later tested.\n",
    "    It consist of one input layer, one output layer and multiple hidden layers.\n",
    "    ...\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim, dropout=0.5):\n",
    "        super(MolNet, self).__init__()\n",
    "        # Layer definitions\n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(input_dim, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(128, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        return self.layers(x)\n",
    "\n",
    "model_mlp = MolNet(input_dim=input_dim, output_dim=output_dim).to(set_device)\n",
    "criterion = nn.CrossEntropyLoss().to(set_device)\n",
    "optimizer = getattr(optim, \"Adam\")(model_mlp.parameters(), lr=args.lr)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch import sigmoid\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "def flat_auroc_score(preds, labels):\n",
    "    \"\"\"\n",
    "    Function to calculate the roc_auc_score of our predictions vs labels\n",
    "    \"\"\"\n",
    "    pred_flat = softmax(preds, dim=1)[:, 1]\n",
    "    # labels_flat = np.argmax(labels, axis=1)\n",
    "    return roc_auc_score(labels, pred_flat.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0.0\n",
    "train_loss_history, recall_train_history = [], []\n",
    "validation_loss_history, recall_validation_history = list(), list()\n",
    "for epoch in range(0, args.epoch):\n",
    "        model_mlp.train()\n",
    "        train_loss_scores = []\n",
    "        training_acc_scores = []\n",
    "        y_pred, y_true= list(), list()\n",
    "        predictions = []\n",
    "        for batch, targets in train_dataloader:\n",
    "            \n",
    "            ## perform forward pass  \n",
    "            batch = batch.type(torch.FloatTensor).to(set_device)\n",
    "            pred = model_mlp(batch) \n",
    "            \n",
    "            preds = torch.max(pred, 1)[1]\n",
    "\n",
    "            ## accumulate predictions per batch for the epoch\n",
    "            y_pred += list([x.item() for x in preds.detach().cpu().numpy()])\n",
    "            targets = torch.LongTensor([x.item() for x in list(targets)])\n",
    "            y_true +=  list([x.item() for x in targets.detach().cpu().numpy()])\n",
    "            \n",
    "            ## compute loss and perform backward pass\n",
    "            loss = criterion(pred.to(set_device), targets.to(set_device)) ## compute loss \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "            \n",
    "            predictions.append(pred)\n",
    "\n",
    "            ## accumulate train loss\n",
    "            train_loss_scores.append(loss.item())\n",
    "        \n",
    "        ## accumulate loss, recall, f1, precision per epoch\n",
    "        train_loss_history.append((sum(train_loss_scores)/len(train_loss_scores)))\n",
    "        #recall = flat_auroc_score(predictions, y_true)\n",
    "        #recall_train_history.append(recall)\n",
    "        print(f'Training =>  Epoch : {epoch+1} | Loss : {train_loss_history[-1]}') \n",
    "              #| AUROC score: {recall_train_history[-1]}')\n",
    "        \n",
    "        model_mlp.eval()\n",
    "        predictions = None\n",
    "        with torch.no_grad():\n",
    "            validation_loss_scores = list()\n",
    "            y_true_val, y_pred_val= list(), list()\n",
    "\n",
    "            ## perform validation pass\n",
    "            for batch, targets in val_dataloader:\n",
    "                ## perform forward pass  \n",
    "                batch = batch.type(torch.FloatTensor).to(set_device)\n",
    "                pred = model_mlp(batch) \n",
    "                predictions = pred\n",
    "                preds = torch.max(pred, 1)[1]\n",
    "                \n",
    "                ## accumulate predictions per batch for the epoch\n",
    "                y_pred_val += list([x.item() for x in preds.detach().cpu().numpy()])\n",
    "                targets = torch.LongTensor([x.item() for x in list(targets)])\n",
    "                y_true_val +=  list([x.item() for x in targets.detach().cpu().numpy()])\n",
    "                \n",
    "                ## computing validate loss\n",
    "                loss = criterion(pred.to(set_device), targets.to(set_device)) ## compute loss \n",
    "\n",
    "                ## accumulate validate loss\n",
    "                validation_loss_scores.append(loss.item())\n",
    "                \n",
    "            \n",
    "            ## accumulate loss, recall, f1, precision per epoch\n",
    "            validation_loss_history.append((sum(validation_loss_scores)/len(validation_loss_scores)))\n",
    "            recall = flat_auroc_score(predictions, y_true_val)\n",
    "            recall_validation_history.append(recall)\n",
    "\n",
    "            print(f'Validation =>  Epoch : {epoch+1} | Loss : {validation_loss_history[-1]} | AUROC score: {recall_validation_history[-1]} ')\n",
    "            \n",
    "            if recall_validation_history[-1]>best_accuracy:\n",
    "                best_accuracy = recall_validation_history[-1]\n",
    "                print('Selecting the model...')\n",
    "                best_model = model_mlp\n",
    "\n",
    "best_model.eval()\n",
    "predictions = None\n",
    "with torch.no_grad():\n",
    "    validation_loss_scores = list()\n",
    "    y_true_val, y_pred_val= list(), list()\n",
    "\n",
    "    ## perform validation pass\n",
    "    for batch, targets in test_dataloader:\n",
    "        ## perform forward pass  \n",
    "        batch = batch.type(torch.FloatTensor).to(set_device)\n",
    "        pred = best_model(batch) \n",
    "        predictions = pred\n",
    "        preds = torch.max(pred, 1)[1]\n",
    "\n",
    "        ## accumulate predictions per batch for the epoch\n",
    "        y_pred_val += list([x.item() for x in preds.detach().cpu().numpy()])\n",
    "        targets = torch.LongTensor([x.item() for x in list(targets)])\n",
    "        y_true_val +=  list([x.item() for x in targets.detach().cpu().numpy()])\n",
    "\n",
    "        ## computing validate loss\n",
    "        loss = criterion(pred.to(set_device), targets.to(set_device)) ## compute loss \n",
    "\n",
    "        ## accumulate validate loss\n",
    "        validation_loss_scores.append(loss.item())\n",
    "\n",
    "\n",
    "    ## accumulate loss, recall, f1, precision per epoch\n",
    "    validation_loss_history.append((sum(validation_loss_scores)/len(validation_loss_scores)))\n",
    "    recall = flat_auroc_score(predictions, y_true_val)\n",
    "    recall_validation_history.append(recall)\n",
    "\n",
    "    print(f'Test => AUROC score: {recall_validation_history[-1]} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a5f15f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50d9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e90d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
